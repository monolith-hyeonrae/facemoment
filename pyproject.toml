[project]
name = "facemoment"
version = "0.1.0"
description = "Face moment detection and highlight clip extraction for 981park"
requires-python = ">=3.10"
dependencies = [
    "visualbase",
    "visualpath",
    "numpy>=1.24.0",
    "opencv-python>=4.8.0",
]

[project.optional-dependencies]
# === Worker dependencies (isolated venvs) ===
# Each worker runs in its own venv with minimal dependencies.
# See: visualpath.process.VenvWorker
#
# Fine-grained extras for venv isolation (Phase 15 분리 extractor):
#   venv-face-detect:  uv pip install -e ".[face-detect]"   → onnxruntime-gpu
#   venv-expression:   uv pip install -e ".[expression]"    → onnxruntime (CPU)
#   venv-face (legacy): uv pip install -e ".[face]"         → 둘 다 포함
#
# face_detect 결과는 deps로 expression venv에 ZMQ 전달되므로
# expression venv에 insightface/onnxruntime-gpu가 필요 없습니다.

face-detect = [
    "insightface>=0.7.3",
    "onnxruntime-gpu>=1.16.0",
    "ml-dtypes>=0.5.0",
]
expression = [
    "hsemotion-onnx>=0.3",
]
# face-classifier: base 의존성만으로 충분 (순수 Python 로직)

# Legacy composite extra (face-detect + expression in one venv)
face = [
    "facemoment[face-detect,expression]",
]
pose = [
    "ultralytics>=8.0.0",
]
gesture = [
    "mediapipe>=0.10.32",
]

# === Local development ===
# For running everything in a single environment (may have conflicts!)

local = [
    "facemoment[face,pose,gesture]",
    "pyzmq>=25.0.0",
    "pyqt6>=6.10.2",
    "supervision>=0.19.0",
    "pathway>=0.8.0",
]
dev = [
    "pytest>=7.0.0",
]

[project.scripts]
facemoment = "facemoment.cli:main"

# Register extractors and fusions as plugins for visualpath
[project.entry-points."visualpath.extractors"]
face = "facemoment.moment_detector.extractors.face:FaceExtractor"
face_detect = "facemoment.moment_detector.extractors.face_detect:FaceDetectionExtractor"
expression = "facemoment.moment_detector.extractors.expression:ExpressionExtractor"
face_classifier = "facemoment.moment_detector.extractors.face_classifier:FaceClassifierExtractor"
pose = "facemoment.moment_detector.extractors.pose:PoseExtractor"
gesture = "facemoment.moment_detector.extractors.gesture:GestureExtractor"
quality = "facemoment.moment_detector.extractors.quality:QualityExtractor"
dummy = "facemoment.moment_detector.extractors.dummy:DummyExtractor"

[project.entry-points."visualpath.fusions"]
highlight = "facemoment.moment_detector.fusion.highlight:HighlightFusion"
dummy = "facemoment.moment_detector.fusion.dummy:DummyFusion"

[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[tool.hatch.build.targets.wheel]
packages = ["src/facemoment"]

[tool.pytest.ini_options]
testpaths = ["tests"]
python_files = ["test_*.py"]
python_classes = ["Test*"]
python_functions = ["test_*"]

[tool.uv.sources]
visualbase = { path = "../visualbase", editable = true }
visualpath = { path = "../visualpath", editable = true }

# CRITICAL: hsemotion-onnx depends on "onnxruntime" (CPU-only wheel).
# When both onnxruntime and onnxruntime-gpu are installed, the CPU package
# overwrites the GPU pybind11 .so, silently disabling CUDAExecutionProvider.
#
# Fix: block the onnxruntime (CPU) package entirely via impossible marker.
# onnxruntime-gpu provides the identical "onnxruntime" Python module with
# CUDA/TensorRT providers, so hsemotion-onnx works fine at runtime.
#
# In production VenvWorker isolates each extractor, but for local
# development (--extra local) this override is essential.
#[tool.uv]
#override-dependencies = [
#    "onnxruntime ; sys_platform == 'never'",
#]
